# GNNassisted_Sampling (Readme still in construction)

This is PyTorch-geometric based Grah Neural Network (GNN) implementation for GNN-assisted sampling. The GNN provides importance scores to blocks of input data (Nyx cosmology simulation dataset) based on the presence of Halos in them thereby telling which blocks are more important than the others for sampling.  
TO DO: Add modified pystk library to perform sampling and reconstruction in parallel on the input blocks.

## GNN Training

1. For converting Nyx cosmology input files (.h5 format file) to numpy arrays (.npy format file) for GNN training run: 
`python H5ToNpy_block_processing.py --input <path_to_h5_file> --Reeberoutfile <path_to_Reeberoutputfile_csv> --block_size 8 --use train`

Note: 
1) --Reeberoutfile refers to the output file generated by the Reeber Halo finder when run on the --input. This is needed for supervised GNN training since the block labels would be determined using the Reeber output file.  
2) --block_size determines the block size the input will be divided into and ultimately the graph sizes the GNN would be trained on. Right now block_size = 8 provides the best results. 
3) When --use is 'train', the .npy file that is generated by the H5ToNpy_block_processing.py code is a class-balanced (equal labels or equal Halo and non Halo blocks) training set.
4) While the input is 512 cube or higher h5 format Nyx dataset, the output are 1) 4D input data numpy array (block_size, block_size, block_size, No_of_blocks) and, 2) 1D block label numpy array (No_of_blocks) .npy files.

After running the code, 2 files namely: training_data_<block_size>cub.npy and training_label_<block_size>cub.npy should be generated.

2. For GNN training run: 
`python GNN_training.py --training_data training_data_<block_size>cub_42.npy --training_label training_labels_<block_size>cub_42.npy --prediction_data /Users/sonalj/Desktop/GNNPytorch/training_data_8cub_42.npy --prediction_label /Users/sonalj/Desktop/GNNPytorch/training_data_8cub_42.npy`

At the end of the code, a trained model file would be saved with the name 'trainedGNN.pt'


## GNN Prediction perfromance:

1. For converting Nyx cosmology input files (.h5 format file) to numpy arrays (.npy format file) for GNN prediction performance analysis run: 
`python H5ToNpy_block_processing.py --input <path_to_h5_file> --Reeberoutfile <path_to_Reeberoutputfile_csv> --block_size 8 --use predict`

Note: 
1) --Reeberoutfile refers to the output file generated by the Reeber Halo finder when run on the --input. This is needed for GNN prediction performance evaluation against the true block labels.  
2) --block_size determines the block size the input will be divided into and ultimately the graph sizes the GNN would be trained on. Right now block_size = 8 provides the best results. 
3) When --use is 'predict', the .npy file that is generated by the H5ToNpy_block_processing.py code is full cube data, the output are 1) 4D input data numpy array (block_size, block_size, block_size, No-of_blocks) and, 2) 1D block label numpy array (No_of_blocks) .npy files.

After running the code, 2 files namely: prediction_data_<block_size>cub.npy and prediction_label_<block_size>cub.npy should be generated.

2. For GNN prediction performance analysis run: 
`python GNN_training.py --training_data training_data_<block_size>cub_42.npy --training_label training_labels_<block_size>cub_42.npy --prediction_data /Users/sonalj/Desktop/GNNPytorch/training_data_8cub_42.npy --prediction_label /Users/sonalj/Desktop/GNNPytorch/training_data_8cub_42.npy`

## GNN Block scoring:

python GNN_BlockScoring.py --input /Users/sonalj/Desktop/GNNPytorch/training_data_8cub_42.npy --label /Users/sonalj/Desktop/GNNPytorch/training_labels_8cub_42.npy 
